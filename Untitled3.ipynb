{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f8d999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_score   -0.120703\n",
      "Open               0.991182\n",
      "High               0.996195\n",
      "Low                0.995533\n",
      "Close              1.000000\n",
      "Out               -0.103699\n",
      "Name: Close, dtype: float64\n",
      "---dataframe head---\n",
      "                  Open        High         Low       Close  sentiment_score\n",
      "Date                                                                       \n",
      "2020-11-01  394.000000  406.980000  392.300000  400.500000         0.305093\n",
      "2020-11-02  394.000000  406.980011  392.299988  400.510010         0.061635\n",
      "2020-11-03  409.730011  427.769989  406.690002  423.899994         0.180670\n",
      "2020-11-04  430.619995  435.399994  417.100006  420.980011         0.534486\n",
      "2020-11-05  428.299988  440.000000  424.000000  438.089996         0.279628\n",
      "--scaling data---\n",
      "--shapes--\n",
      "train,test,val (237, 5) (79, 5) (79, 5)\n",
      "x_train (177, 60, 5)\n",
      "y_train (177,)\n",
      "x_test (19, 60, 5)\n",
      "y_test (19,)\n",
      "x_val (19, 60, 5)\n",
      "y_val (19,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 21:10:31.088613: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-12-06 21:10:31.088636: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-12-06 21:10:31.088869: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 60, 600)           1454400   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 700)               3642800   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 700)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 701       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,097,901\n",
      "Trainable params: 5,097,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start: 0\n",
      "Epoch 1/400\n",
      "6/6 [==============================] - 6s 637ms/step - loss: 0.1933 - val_loss: 0.0234\n",
      "Epoch 2/400\n",
      "6/6 [==============================] - 3s 479ms/step - loss: 0.0301 - val_loss: 0.0346\n",
      "Epoch 3/400\n",
      "6/6 [==============================] - 3s 470ms/step - loss: 0.0248 - val_loss: 0.0040\n",
      "Epoch 4/400\n",
      "6/6 [==============================] - 3s 497ms/step - loss: 0.0098 - val_loss: 4.9921e-04\n",
      "Epoch 5/400\n",
      "6/6 [==============================] - 3s 480ms/step - loss: 0.0029 - val_loss: 0.0061\n",
      "Epoch 6/400\n",
      "6/6 [==============================] - 3s 476ms/step - loss: 0.0045 - val_loss: 5.1426e-04\n",
      "Epoch 7/400\n",
      "6/6 [==============================] - 3s 477ms/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 8/400\n",
      "6/6 [==============================] - 3s 478ms/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 9/400\n",
      "6/6 [==============================] - 3s 477ms/step - loss: 0.0026 - val_loss: 4.9661e-04\n",
      "Epoch 10/400\n",
      "6/6 [==============================] - 3s 471ms/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 11/400\n",
      "6/6 [==============================] - 3s 483ms/step - loss: 0.0026 - val_loss: 4.3130e-04\n",
      "Epoch 12/400\n",
      "6/6 [==============================] - 3s 479ms/step - loss: 0.0023 - val_loss: 6.2394e-04\n",
      "Epoch 13/400\n",
      "6/6 [==============================] - 3s 476ms/step - loss: 0.0022 - val_loss: 6.0365e-04\n",
      "Epoch 14/400\n",
      "6/6 [==============================] - 3s 475ms/step - loss: 0.0022 - val_loss: 4.0587e-04\n",
      "Epoch 15/400\n",
      "6/6 [==============================] - 3s 495ms/step - loss: 0.0022 - val_loss: 5.2709e-04\n",
      "Epoch 16/400\n",
      "6/6 [==============================] - 3s 481ms/step - loss: 0.0021 - val_loss: 4.0002e-04\n",
      "Epoch 17/400\n",
      "6/6 [==============================] - 3s 561ms/step - loss: 0.0022 - val_loss: 4.2894e-04\n",
      "Epoch 18/400\n",
      "6/6 [==============================] - 3s 523ms/step - loss: 0.0020 - val_loss: 3.8335e-04\n",
      "Epoch 19/400\n",
      "6/6 [==============================] - 3s 507ms/step - loss: 0.0021 - val_loss: 3.5047e-04\n",
      "Epoch 20/400\n",
      "6/6 [==============================] - 3s 489ms/step - loss: 0.0020 - val_loss: 3.2966e-04\n",
      "Epoch 21/400\n",
      "6/6 [==============================] - 3s 488ms/step - loss: 0.0020 - val_loss: 3.6942e-04\n",
      "Epoch 22/400\n",
      "6/6 [==============================] - 3s 481ms/step - loss: 0.0019 - val_loss: 3.2562e-04\n",
      "Epoch 23/400\n",
      "6/6 [==============================] - 3s 485ms/step - loss: 0.0019 - val_loss: 3.7044e-04\n",
      "Epoch 24/400\n",
      "6/6 [==============================] - 3s 491ms/step - loss: 0.0019 - val_loss: 3.0549e-04\n",
      "Epoch 25/400\n",
      "6/6 [==============================] - 3s 479ms/step - loss: 0.0019 - val_loss: 3.2187e-04\n",
      "Epoch 26/400\n",
      "6/6 [==============================] - 3s 480ms/step - loss: 0.0018 - val_loss: 2.5387e-04\n",
      "Epoch 27/400\n",
      "6/6 [==============================] - 3s 491ms/step - loss: 0.0018 - val_loss: 3.6192e-04\n",
      "Epoch 28/400\n",
      "6/6 [==============================] - 3s 485ms/step - loss: 0.0020 - val_loss: 2.6515e-04\n",
      "Epoch 29/400\n",
      "6/6 [==============================] - 3s 511ms/step - loss: 0.0018 - val_loss: 4.0508e-04\n",
      "Epoch 30/400\n",
      "6/6 [==============================] - 3s 481ms/step - loss: 0.0020 - val_loss: 2.4683e-04\n",
      "Epoch 31/400\n",
      "6/6 [==============================] - 3s 491ms/step - loss: 0.0017 - val_loss: 3.4363e-04\n",
      "Epoch 32/400\n",
      "6/6 [==============================] - 3s 495ms/step - loss: 0.0019 - val_loss: 3.1108e-04\n",
      "Epoch 33/400\n",
      "6/6 [==============================] - 3s 477ms/step - loss: 0.0016 - val_loss: 2.2757e-04\n",
      "Epoch 34/400\n",
      "6/6 [==============================] - 3s 540ms/step - loss: 0.0017 - val_loss: 4.8190e-04\n",
      "Epoch 35/400\n",
      "6/6 [==============================] - 3s 480ms/step - loss: 0.0017 - val_loss: 2.6770e-04\n",
      "Epoch 36/400\n",
      "6/6 [==============================] - 3s 487ms/step - loss: 0.0017 - val_loss: 2.1030e-04\n",
      "Epoch 37/400\n",
      "6/6 [==============================] - 3s 508ms/step - loss: 0.0017 - val_loss: 4.1923e-04\n",
      "Epoch 38/400\n",
      "6/6 [==============================] - 3s 512ms/step - loss: 0.0017 - val_loss: 3.6492e-04\n",
      "Epoch 39/400\n",
      "6/6 [==============================] - 3s 488ms/step - loss: 0.0017 - val_loss: 2.2588e-04\n",
      "Epoch 40/400\n",
      "6/6 [==============================] - 3s 498ms/step - loss: 0.0016 - val_loss: 4.1089e-04\n",
      "Epoch 41/400\n",
      "6/6 [==============================] - 3s 514ms/step - loss: 0.0017 - val_loss: 4.1480e-04\n",
      "Epoch 42/400\n",
      "6/6 [==============================] - 3s 498ms/step - loss: 0.0016 - val_loss: 2.7781e-04\n",
      "Epoch 43/400\n",
      "6/6 [==============================] - 3s 487ms/step - loss: 0.0016 - val_loss: 2.4782e-04\n",
      "Epoch 44/400\n",
      "6/6 [==============================] - 3s 488ms/step - loss: 0.0015 - val_loss: 5.3951e-04\n",
      "Epoch 45/400\n",
      "6/6 [==============================] - 3s 489ms/step - loss: 0.0016 - val_loss: 3.8045e-04\n",
      "Epoch 46/400\n",
      "6/6 [==============================] - 3s 485ms/step - loss: 0.0016 - val_loss: 2.5115e-04\n",
      "Epoch 47/400\n",
      "6/6 [==============================] - 3s 484ms/step - loss: 0.0015 - val_loss: 2.0806e-04\n",
      "Epoch 48/400\n",
      "6/6 [==============================] - 3s 487ms/step - loss: 0.0015 - val_loss: 7.4584e-04\n",
      "Epoch 49/400\n",
      "6/6 [==============================] - 3s 477ms/step - loss: 0.0019 - val_loss: 4.2090e-04\n",
      "Epoch 50/400\n",
      "6/6 [==============================] - 3s 466ms/step - loss: 0.0016 - val_loss: 2.1693e-04\n",
      "Epoch 51/400\n",
      "6/6 [==============================] - 3s 462ms/step - loss: 0.0016 - val_loss: 2.0130e-04\n",
      "Epoch 52/400\n",
      "6/6 [==============================] - 3s 474ms/step - loss: 0.0014 - val_loss: 7.7168e-04\n",
      "Epoch 53/400\n",
      "6/6 [==============================] - 3s 473ms/step - loss: 0.0019 - val_loss: 3.9845e-04\n",
      "Epoch 54/400\n",
      "6/6 [==============================] - 3s 492ms/step - loss: 0.0016 - val_loss: 2.0690e-04\n",
      "Epoch 55/400\n",
      "6/6 [==============================] - 3s 476ms/step - loss: 0.0015 - val_loss: 3.4811e-04\n",
      "Epoch 56/400\n",
      "6/6 [==============================] - 3s 467ms/step - loss: 0.0015 - val_loss: 4.1591e-04\n",
      "Epoch 57/400\n",
      "6/6 [==============================] - 3s 489ms/step - loss: 0.0016 - val_loss: 2.5137e-04\n",
      "Epoch 58/400\n",
      "6/6 [==============================] - 3s 471ms/step - loss: 0.0014 - val_loss: 2.4069e-04\n",
      "Epoch 59/400\n",
      "6/6 [==============================] - 3s 475ms/step - loss: 0.0014 - val_loss: 3.1275e-04\n",
      "Epoch 60/400\n",
      "6/6 [==============================] - 3s 504ms/step - loss: 0.0014 - val_loss: 3.4940e-04\n",
      "Epoch 61/400\n",
      "6/6 [==============================] - 3s 493ms/step - loss: 0.0016 - val_loss: 2.3730e-04\n",
      "Epoch 62/400\n",
      "6/6 [==============================] - 3s 481ms/step - loss: 0.0014 - val_loss: 2.2835e-04\n",
      "Epoch 63/400\n",
      "6/6 [==============================] - 3s 476ms/step - loss: 0.0014 - val_loss: 2.2546e-04\n",
      "Epoch 64/400\n",
      "6/6 [==============================] - 3s 487ms/step - loss: 0.0015 - val_loss: 2.8620e-04\n",
      "Epoch 65/400\n",
      "6/6 [==============================] - 3s 480ms/step - loss: 0.0014 - val_loss: 3.9814e-04\n",
      "Epoch 66/400\n",
      "6/6 [==============================] - 3s 492ms/step - loss: 0.0015 - val_loss: 2.3832e-04\n",
      "Epoch 67/400\n",
      "6/6 [==============================] - 3s 488ms/step - loss: 0.0015 - val_loss: 1.7919e-04\n",
      "Epoch 68/400\n",
      "6/6 [==============================] - 3s 478ms/step - loss: 0.0015 - val_loss: 4.5307e-04\n",
      "Epoch 69/400\n",
      "6/6 [==============================] - 3s 473ms/step - loss: 0.0016 - val_loss: 3.1552e-04\n",
      "Epoch 70/400\n",
      "6/6 [==============================] - 3s 473ms/step - loss: 0.0014 - val_loss: 2.1770e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/400\n",
      "6/6 [==============================] - 3s 472ms/step - loss: 0.0014 - val_loss: 2.5724e-04\n",
      "Epoch 72/400\n",
      "6/6 [==============================] - 3s 478ms/step - loss: 0.0013 - val_loss: 5.5587e-04\n",
      "Epoch 73/400\n",
      "6/6 [==============================] - 3s 481ms/step - loss: 0.0016 - val_loss: 2.9837e-04\n",
      "Epoch 74/400\n",
      "6/6 [==============================] - 3s 473ms/step - loss: 0.0014 - val_loss: 2.4264e-04\n",
      "Epoch 75/400\n",
      "6/6 [==============================] - 3s 496ms/step - loss: 0.0014 - val_loss: 2.5825e-04\n",
      "Epoch 76/400\n",
      "6/6 [==============================] - 3s 488ms/step - loss: 0.0012 - val_loss: 4.2684e-04\n",
      "Epoch 77/400\n",
      "6/6 [==============================] - 3s 477ms/step - loss: 0.0015 - val_loss: 4.9720e-04\n",
      "Epoch 78/400\n",
      "6/6 [==============================] - 3s 490ms/step - loss: 0.0016 - val_loss: 2.3464e-04\n",
      "Epoch 79/400\n",
      "6/6 [==============================] - 3s 488ms/step - loss: 0.0014 - val_loss: 2.5499e-04\n",
      "Epoch 80/400\n",
      "6/6 [==============================] - 3s 491ms/step - loss: 0.0014 - val_loss: 2.4219e-04\n",
      "Epoch 81/400\n",
      "6/6 [==============================] - 3s 478ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 82/400\n",
      "6/6 [==============================] - 3s 481ms/step - loss: 0.0018 - val_loss: 2.3150e-04\n",
      "Epoch 83/400\n",
      "6/6 [==============================] - 3s 474ms/step - loss: 0.0015 - val_loss: 4.1920e-04\n",
      "Epoch 84/400\n",
      "6/6 [==============================] - 3s 471ms/step - loss: 0.0015 - val_loss: 6.2890e-04\n",
      "Epoch 85/400\n",
      "6/6 [==============================] - 3s 483ms/step - loss: 0.0018 - val_loss: 5.6303e-04\n",
      "Epoch 86/400\n",
      "6/6 [==============================] - 3s 469ms/step - loss: 0.0015 - val_loss: 1.7689e-04\n",
      "Epoch 87/400\n",
      "6/6 [==============================] - 3s 471ms/step - loss: 0.0014 - val_loss: 2.4417e-04\n",
      "Epoch 88/400\n",
      "6/6 [==============================] - 3s 484ms/step - loss: 0.0013 - val_loss: 2.4817e-04\n",
      "Epoch 89/400\n",
      "6/6 [==============================] - 3s 530ms/step - loss: 0.0013 - val_loss: 1.7123e-04\n",
      "Epoch 90/400\n",
      "6/6 [==============================] - 3s 471ms/step - loss: 0.0012 - val_loss: 3.9299e-04\n",
      "Epoch 91/400\n",
      "6/6 [==============================] - 3s 497ms/step - loss: 0.0014 - val_loss: 2.1030e-04\n",
      "Epoch 92/400\n",
      "6/6 [==============================] - 3s 531ms/step - loss: 0.0013 - val_loss: 2.1185e-04\n",
      "Epoch 93/400\n",
      "6/6 [==============================] - 3s 477ms/step - loss: 0.0012 - val_loss: 2.2513e-04\n",
      "Epoch 94/400\n",
      "6/6 [==============================] - 3s 488ms/step - loss: 0.0012 - val_loss: 2.4766e-04\n",
      "Epoch 95/400\n",
      "6/6 [==============================] - 3s 499ms/step - loss: 0.0013 - val_loss: 2.6640e-04\n",
      "Epoch 96/400\n",
      "6/6 [==============================] - 3s 486ms/step - loss: 0.0013 - val_loss: 3.1866e-04\n",
      "Epoch 97/400\n",
      "6/6 [==============================] - 3s 496ms/step - loss: 0.0011 - val_loss: 2.2649e-04\n",
      "Epoch 98/400\n",
      "6/6 [==============================] - 3s 478ms/step - loss: 0.0012 - val_loss: 1.9463e-04\n",
      "Epoch 99/400\n",
      "6/6 [==============================] - 3s 470ms/step - loss: 0.0012 - val_loss: 3.2764e-04\n",
      "Epoch 100/400\n",
      "6/6 [==============================] - 3s 485ms/step - loss: 0.0013 - val_loss: 4.2507e-04\n",
      "Epoch 101/400\n",
      "6/6 [==============================] - 3s 499ms/step - loss: 0.0014 - val_loss: 2.0378e-04\n",
      "Epoch 102/400\n",
      "6/6 [==============================] - 3s 476ms/step - loss: 0.0012 - val_loss: 2.4570e-04\n",
      "Epoch 103/400\n",
      "6/6 [==============================] - 3s 479ms/step - loss: 0.0012 - val_loss: 4.1713e-04\n",
      "Epoch 104/400\n",
      "6/6 [==============================] - 3s 469ms/step - loss: 0.0014 - val_loss: 1.8355e-04\n",
      "Epoch 105/400\n",
      "6/6 [==============================] - 3s 479ms/step - loss: 0.0012 - val_loss: 1.6961e-04\n",
      "Epoch 106/400\n",
      "6/6 [==============================] - 3s 486ms/step - loss: 0.0012 - val_loss: 6.2307e-04\n",
      "Epoch 00106: early stopping\n",
      "endtime: 310.97559213638306\n",
      "r2_score: -2.806721944213503\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from time import time\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "\n",
    "df = pd.read_csv(\"twitter_training.csv\",parse_dates=True,index_col=\"Date\")\n",
    "# df = df[1563:]\n",
    "print(df.corr()['Close'])\n",
    "df = df[['Open', 'High', 'Low','Close','sentiment_score']]\n",
    "print(\"---dataframe head---\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"--scaling data---\")\n",
    "data = sc.fit_transform(df) \n",
    "train_ind = int(0.6*len(df))\n",
    "val_ind = train_ind + int(0.2*len(df))\n",
    "\n",
    "train = data[:train_ind]\n",
    "val = data[train_ind:val_ind]\n",
    "test = data[val_ind:]\n",
    "\n",
    "print(\"--shapes--\")\n",
    "print(\"train,test,val\",train.shape, test.shape, val.shape)\n",
    "\n",
    "xtrain,ytrain,xval,yval,xtest,ytest = train[:,:5],train[:,3],val[:,:5],val[:,3],test[:,:5],test[:,3]\n",
    "\n",
    "lookback = 60\n",
    "n_features = 5\n",
    "train_len = len(xtrain) - lookback\n",
    "test_len = len(xtest) - lookback\n",
    "val_len = len(xval) - lookback\n",
    "\n",
    "x_train = np.zeros((train_len, lookback, n_features))\n",
    "y_train = np.zeros((train_len))\n",
    "for i in range(train_len):\n",
    "    ytemp = i+lookback\n",
    "    x_train[i] = xtrain[i:ytemp]\n",
    "    y_train[i] = ytrain[ytemp]\n",
    "print(\"x_train\", x_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "\n",
    "x_test = np.zeros((test_len, lookback, n_features))\n",
    "y_test = np.zeros((test_len))\n",
    "for i in range(test_len):\n",
    "    ytemp = i+lookback\n",
    "    x_test[i] = xtest[i:ytemp]\n",
    "    y_test[i] = ytest[ytemp]\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"y_test\", y_test.shape)\n",
    "\n",
    "x_val = np.zeros((val_len, lookback, n_features))\n",
    "y_val = np.zeros((val_len))\n",
    "for i in range(val_len):\n",
    "    ytemp = i+lookback\n",
    "    x_val[i] = xval[i:ytemp]\n",
    "    y_val[i] = yval[ytemp]\n",
    "print(\"x_val\", x_val.shape)\n",
    "print(\"y_val\", y_val.shape)\n",
    "\n",
    "model = Sequential()  \n",
    "model.add(LSTM(600,input_shape = (lookback, n_features), return_sequences=True))\n",
    "model.add(LSTM(700))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(1))\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss = 'mse', optimizer = 'adam')\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=80,  verbose=1, mode='min')\n",
    "\n",
    "start = time()\n",
    "print(\"start:\",0)\n",
    "history = model.fit(x_train,y_train, epochs = 400, batch_size=30, \n",
    "          validation_data=(x_val,y_val),verbose = 1, \n",
    "          shuffle = False, callbacks=[earlystop])\n",
    "print(\"endtime:\",time()-start)\n",
    "\n",
    "model.save(\"./models/model_vader7.h5\")\n",
    "loss = history.history\n",
    "plt.plot(loss['loss'])\n",
    "plt.plot(loss['val_loss'])\n",
    "plt.savefig(\"./plots/loss_vader7.jpg\")\n",
    "\n",
    "model.save(\"./models/model_vader6.h5\")\n",
    "loss = history.history\n",
    "plt.plot(loss['loss'])\n",
    "plt.plot(loss['val_loss'])\n",
    "plt.savefig(\"./plots/loss_vader6.jpg\")\n",
    "plt.show()\n",
    "# model = load_model(\"./models/model_vader1.h5\")\n",
    "y_pred = model.predict(x_test)\n",
    "# print(model.summary())\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot( y_test, '.-', color='red', label='Real values', alpha=0.5)\n",
    "plt.plot( y_pred, '.-', color='blue', label='Predicted values', alpha=1)\n",
    "plt.savefig(\"./plots/result_vader7.jpg\")\n",
    "plt.savefig(\"./plots/result_vader6.jpg\")\n",
    "plt.show()\n",
    "\n",
    "print(\"r2_score:\",r2_score(y_pred,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9deb78bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = model.predict(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "057a98c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.31742042]\n",
      " [0.33421808]\n",
      " [0.35309458]\n",
      " [0.37066546]\n",
      " [0.36695448]\n",
      " [0.37783983]\n",
      " [0.3885431 ]\n",
      " [0.39514163]\n",
      " [0.42937177]\n",
      " [0.4796895 ]\n",
      " [0.52030575]\n",
      " [0.5540923 ]\n",
      " [0.5349953 ]\n",
      " [0.53298104]\n",
      " [0.5292028 ]\n",
      " [0.52582407]\n",
      " [0.51204866]\n",
      " [0.49777865]\n",
      " [0.49247304]\n",
      " [0.4887007 ]\n",
      " [0.50710636]\n",
      " [0.50794363]\n",
      " [0.50584584]\n",
      " [0.5105157 ]\n",
      " [0.51085544]\n",
      " [0.5089895 ]\n",
      " [0.5159109 ]\n",
      " [0.5190889 ]\n",
      " [0.5137817 ]\n",
      " [0.5096271 ]\n",
      " [0.48684877]\n",
      " [0.46030325]\n",
      " [0.44942153]\n",
      " [0.46424833]\n",
      " [0.4920578 ]\n",
      " [0.49938673]\n",
      " [0.4916763 ]\n",
      " [0.51518637]\n",
      " [0.52112204]\n",
      " [0.5176707 ]\n",
      " [0.5112549 ]\n",
      " [0.49521303]\n",
      " [0.47761145]\n",
      " [0.46143222]\n",
      " [0.4722612 ]\n",
      " [0.4662333 ]\n",
      " [0.46289754]\n",
      " [0.4548308 ]\n",
      " [0.44303182]\n",
      " [0.43738368]\n",
      " [0.43244267]\n",
      " [0.42498234]\n",
      " [0.41935176]\n",
      " [0.41241542]\n",
      " [0.3942393 ]\n",
      " [0.371534  ]\n",
      " [0.3725206 ]\n",
      " [0.35088637]\n",
      " [0.32992068]\n",
      " [0.31057063]\n",
      " [0.30827516]\n",
      " [0.3273695 ]\n",
      " [0.3336131 ]\n",
      " [0.31723312]\n",
      " [0.2902079 ]\n",
      " [0.25688523]\n",
      " [0.24043038]\n",
      " [0.23176308]\n",
      " [0.21848054]\n",
      " [0.2428351 ]\n",
      " [0.27089915]\n",
      " [0.30884606]\n",
      " [0.3355996 ]\n",
      " [0.34454057]\n",
      " [0.33712116]\n",
      " [0.33525455]\n",
      " [0.31883398]\n",
      " [0.3217996 ]\n",
      " [0.31114677]\n",
      " [0.31503245]\n",
      " [0.31390154]\n",
      " [0.30737832]\n",
      " [0.29352668]\n",
      " [0.28840107]\n",
      " [0.28767148]\n",
      " [0.29167014]\n",
      " [0.27896985]\n",
      " [0.27464268]\n",
      " [0.2668947 ]\n",
      " [0.256961  ]\n",
      " [0.26439628]\n",
      " [0.28098086]\n",
      " [0.2905494 ]\n",
      " [0.29537955]\n",
      " [0.30180305]\n",
      " [0.3181916 ]\n",
      " [0.329739  ]\n",
      " [0.34642863]\n",
      " [0.3339189 ]\n",
      " [0.33381915]\n",
      " [0.3209717 ]\n",
      " [0.3159344 ]\n",
      " [0.30994427]\n",
      " [0.3226849 ]\n",
      " [0.35306835]\n",
      " [0.3778916 ]\n",
      " [0.38385704]\n",
      " [0.4001463 ]\n",
      " [0.40107372]\n",
      " [0.39459753]\n",
      " [0.3659969 ]\n",
      " [0.36415303]\n",
      " [0.3796576 ]\n",
      " [0.3737229 ]\n",
      " [0.3837283 ]\n",
      " [0.38011482]\n",
      " [0.37719107]\n",
      " [0.37346604]\n",
      " [0.3681992 ]\n",
      " [0.3514197 ]\n",
      " [0.33862674]\n",
      " [0.35159504]\n",
      " [0.34896415]\n",
      " [0.3453677 ]\n",
      " [0.3269468 ]\n",
      " [0.3084695 ]\n",
      " [0.30602115]\n",
      " [0.3018199 ]\n",
      " [0.31687346]\n",
      " [0.32537848]\n",
      " [0.32309937]\n",
      " [0.30277896]\n",
      " [0.28151026]\n",
      " [0.24884912]\n",
      " [0.21867454]\n",
      " [0.21304181]\n",
      " [0.22320983]\n",
      " [0.2228283 ]\n",
      " [0.21930711]\n",
      " [0.21272863]\n",
      " [0.21068726]\n",
      " [0.21059889]\n",
      " [0.20400892]\n",
      " [0.20592023]\n",
      " [0.2189549 ]\n",
      " [0.23690942]\n",
      " [0.24275276]\n",
      " [0.2584857 ]\n",
      " [0.2759668 ]\n",
      " [0.2653391 ]\n",
      " [0.2596254 ]\n",
      " [0.26611036]\n",
      " [0.27209458]\n",
      " [0.27184758]\n",
      " [0.26162714]\n",
      " [0.24263746]\n",
      " [0.24102305]\n",
      " [0.24350354]\n",
      " [0.2411562 ]\n",
      " [0.23891382]\n",
      " [0.2339755 ]\n",
      " [0.22140074]\n",
      " [0.2301399 ]\n",
      " [0.23481488]\n",
      " [0.23982757]\n",
      " [0.24846694]\n",
      " [0.26672056]\n",
      " [0.2607989 ]\n",
      " [0.257149  ]\n",
      " [0.26021475]\n",
      " [0.25741827]\n",
      " [0.2624087 ]\n",
      " [0.26028213]\n",
      " [0.24988183]\n",
      " [0.26431644]\n",
      " [0.27872565]\n",
      " [0.3044068 ]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9b2e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
